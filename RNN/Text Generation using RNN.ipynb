{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "purple-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "equivalent-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "supported-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = r'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "single-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_file, 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "military-diary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "black-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "respiratory-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "owned-module",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "pretty-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind, char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "differential-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind_to_char = {ind:char for ind, char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "frequent-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "nearby-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])  ## character to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "physical-relations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "needed-movement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "alert-oxford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "sound-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('From fairest creatures we desire increase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "enhanced-genetics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('''From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-guide",
   "metadata": {},
   "source": [
    "#### creatig batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "structured-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "radical-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "instant-standing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "resistant-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cosmetic-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "binding-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in char_dataset.take(500):\n",
    "#     print(ind_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "hybrid-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "norman-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_target(seq):\n",
    "    input_text = seq[:-1] #hello my nam\n",
    "    target_text = seq[1:] # ello my name\n",
    "    \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "sublime-embassy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function create_sequence_target at 0x000001F6476FAC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function create_sequence_target at 0x000001F6476FAC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(create_sequence_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "occupied-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "___________________________________\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    print(input_text.numpy())\n",
    "    print(\"\".join(ind_to_char[input_text.numpy()]))\n",
    "    print('___________________________________')\n",
    "    print(target_text.numpy())\n",
    "    print(\"\".join(ind_to_char[target_text.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "maritime-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "explicit-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "exciting-event",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-hydrogen",
   "metadata": {},
   "source": [
    "##### creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fifth-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "impaired-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "lyric-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-broadcast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "federal-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "referenced-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "french-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "incorporated-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size,None]))\n",
    "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "pointed-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size=vocab_size,\n",
    "                    embed_dim=embed_dim,\n",
    "                    rnn_neurons=rnn_neurons,\n",
    "                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "inner-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (128, None, 1024)         3348480   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, None, 84)           86100     \n",
      "=================================================================\n",
      "Total params: 3,439,956\n",
      "Trainable params: 3,439,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-workshop",
   "metadata": {},
   "source": [
    "#### train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-terminology",
   "metadata": {},
   "source": [
    "random text geenration for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "exterior-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_prediction = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "angry-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 120, 84])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sharing-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
       "array([[-0.00076059, -0.00338398,  0.00185325, ...,  0.00092757,\n",
       "        -0.00023945, -0.00139248],\n",
       "       [ 0.00030299,  0.00097693,  0.01192942, ..., -0.0046382 ,\n",
       "        -0.00505411, -0.00092662],\n",
       "       [-0.00361676,  0.00446928,  0.00663559, ..., -0.00194609,\n",
       "         0.00337014,  0.00439108],\n",
       "       ...,\n",
       "       [-0.00524939, -0.00503995,  0.00365616, ..., -0.00453976,\n",
       "         0.00734555, -0.00668871],\n",
       "       [-0.00520948, -0.00773752, -0.00819679, ...,  0.00246347,\n",
       "         0.00465396, -0.00449445],\n",
       "       [-0.00449074, -0.00770512, -0.00284968, ...,  0.00144689,\n",
       "         0.00122634, -0.00473004]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "current-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = tf.random.categorical(example_batch_prediction[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "entire-ancient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71, 22, 44, 39, 53, 31, 24, 37,  2,  4, 36, 31, 75, 33, 81, 76, 12,\n",
       "       26, 71, 68, 78, 47, 52, 80, 58, 32, 41, 53, 28, 53, 45,  6,  9, 65,\n",
       "       69, 73,  5, 53, 34,  8, 40,  4, 53,  6, 30, 46, 39,  4, 38, 43, 41,\n",
       "       46, 10, 30, 56, 47,  1, 50, 48, 66,  8, 40, 52, 51, 78, 30, 75, 53,\n",
       "       52,  3, 36, 54, 69, 43, 73, 46, 75, 56, 41, 38, 64, 28, 80, 75,  5,\n",
       "       28, 64,  0, 19, 15, 25, 52, 22, 13,  3, 34, 40,  5, 42, 23, 73, 69,\n",
       "       74, 78, 22, 62, 69, 75, 71, 19, 24, 78,  2, 34, 68, 10, 16, 60, 70,\n",
       "       63], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices = tf.squeeze(sample_indices, axis=-1).numpy()\n",
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "homeless-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p', ';', 'S', 'N', ']', 'F', '>', 'L', '!', '&', 'K', 'F', 't',\n",
       "       'H', 'z', 'u', '1', 'A', 'p', 'm', 'w', 'V', '[', 'y', 'c', 'G',\n",
       "       'P', ']', 'C', ']', 'T', '(', '-', 'j', 'n', 'r', \"'\", ']', 'I',\n",
       "       ',', 'O', '&', ']', '(', 'E', 'U', 'N', '&', 'M', 'R', 'P', 'U',\n",
       "       '.', 'E', 'a', 'V', ' ', 'Y', 'W', 'k', ',', 'O', '[', 'Z', 'w',\n",
       "       'E', 't', ']', '[', '\"', 'K', '_', 'n', 'R', 'r', 'U', 't', 'a',\n",
       "       'P', 'M', 'i', 'C', 'y', 't', \"'\", 'C', 'i', '\\n', '8', '4', '?',\n",
       "       '[', ';', '2', '\"', 'I', 'O', \"'\", 'Q', '<', 'r', 'n', 's', 'w',\n",
       "       ';', 'g', 'n', 't', 'p', '8', '>', 'w', '!', 'I', 'm', '.', '5',\n",
       "       'e', 'o', 'h'], dtype='<U1')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sample_indices]  ### random charcter predcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "interesting-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "##training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "prescribed-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "decent-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shakespeare_gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "alien-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "center-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size=vocab_size,\n",
    "                    embed_dim=embed_dim,\n",
    "                    rnn_neurons=rnn_neurons,\n",
    "                    batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "seventh-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(r'C:\\Users\\user\\Downloads\\Compressed\\FINAL_TF2_FILES\\TF_2_Notebooks_and_Data\\06-NLP-and-Text-Data\\shakespeare_gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "legal-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "geological-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "worthy-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
    "    '''\n",
    "    model: Trained Model to Generate Text\n",
    "    start_seed: Intial Seed text in string form\n",
    "    gen_size: Number of characters to generate\n",
    "\n",
    "    Basic idea behind this function is to take in some seed text, format it so\n",
    "    that it is in the correct shape for our network, then loop the sequence as\n",
    "    we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "    time series problems.\n",
    "    '''\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = gen_size\n",
    "\n",
    "    # Vecotrizing starting seed text\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "    # Expand to match batch format shape\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty list to hold resulting generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Temperature effects randomness in our resulting text\n",
    "    # The term is derived from entropy/thermodynamics.\n",
    "    # The temperature is used to effect probability of next characters.\n",
    "    # Higher probability == lesss surprising/ more expected\n",
    "    # Lower temperature == more surprising / less expected\n",
    "\n",
    "    temperature = temp\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "\n",
    "        # Generate Predictions\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch shape dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Use a cateogircal disitribution to select the next character\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted charracter for the next input\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        # Transform back to character letter\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "    return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "genetic-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juliet:\n",
      "  SALERIO. Mistress Antony, being flexheed, the best, Kate to\n",
      "ANTIPHOLUS OF EPHESUS, and grave me thou ask the mind.\n",
      "  AJAX. It is a creature now our counsel.\n",
      "  ROSALINE. Well, have you heard a friend?\n",
      "  THIRD LORD. Ay, ay some power your guide. Plantagenet sorrow fair.\n",
      "  SHEPHERD. I will not.\n",
      "  SECRET. There is no town among myself, but tell them,\n",
      "    That rich employ'd and was much writ.\n",
      "\n",
      "                    Enter ACHILLES\n",
      "  CURTIN, a\n",
      "                Likest the approaches of the rose,\n",
      "    He makes the rest sleep with spite of it,\n",
      "    Rise and well arred words,\n",
      "    For 'tis a country as his honour\n",
      "    As is contented so.\n",
      "  DIOMEDES. May I gash keep you for a monthamblor?\n",
      "  VOLUMNIA. There twenty you here do forb'd in with\n",
      "    pokes treesters for our upboint a mother on his weapon. Paund for the\n",
      "     pigeorse fit for it; at an ill fearing glad,\n",
      "    Making\n",
      "    Keeps in, with his against he swear not to her; you love thee not?\n",
      "  PATROCLUS. You are old, and cried 'bus' to be neces.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, 'Juliet', gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-suite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
